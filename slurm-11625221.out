add:2,sub:1
0 - SLURM_JOB_ID: 11625221
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 11557
add:2,sub:1
0 - SLURM_JOB_ID: 11625221
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 11557
add:2,sub:1
0 - SLURM_JOB_ID: 11625221
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 11557
add:2,sub:1
0 - SLURM_JOB_ID: 11625221
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 11557
0 - Master address: 127.0.0.1
0 - Master port   : 29500
3 - Number of nodes: 1
3 - Node ID					   : 0
3 - Local rank				   : 3
3 - Global rank    : 3
3 - World size				   : 4
3 - GPUs per node  : 4
3 - Master					   : False
3 - Multi-node				   : False
3 - Multi-GPU				   : True
3 - Hostname				   : hpc-25-17.cm.cluster
Initializing PyTorch distributed ...
0 - Master address: 127.0.0.1
0 - Master port   : 29500
0 - Number of nodes: 1
0 - Node ID					   : 0
0 - Local rank				   : 0
0 - Global rank    : 0
0 - World size				   : 4
0 - GPUs per node  : 4
0 - Master					   : True
0 - Multi-node				   : False
0 - Multi-GPU				   : True
0 - Hostname				   : hpc-25-17.cm.cluster
Initializing PyTorch distributed ...
0 - Master address: 127.0.0.1
0 - Master port   : 29500
1 - Number of nodes: 1
1 - Node ID					   : 0
1 - Local rank				   : 1
1 - Global rank    : 1
1 - World size				   : 4
1 - GPUs per node  : 4
1 - Master					   : False
1 - Multi-node				   : False
1 - Multi-GPU				   : True
1 - Hostname				   : hpc-25-17.cm.cluster
Initializing PyTorch distributed ...
0 - Master address: 127.0.0.1
0 - Master port   : 29500
2 - Number of nodes: 1
2 - Node ID					   : 0
2 - Local rank				   : 2
2 - Global rank    : 2
2 - World size				   : 4
2 - GPUs per node  : 4
2 - Master					   : False
2 - Multi-node				   : False
2 - Multi-GPU				   : True
2 - Hostname				   : hpc-25-17.cm.cluster
Initializing PyTorch distributed ...
INFO - 09/20/20 22:42:55 - 0:00:00 - ============ Initialized logger ============
INFO - 09/20/20 22:42:55 - 0:00:00 - accumulate_gradients: 1
                                     amp: -1
                                     attention_dropout: 0
                                     balanced: False
                                     batch_size: 64
                                     beam_early_stopping: True
                                     beam_eval: False
                                     beam_length_penalty: 1
                                     beam_size: 1
                                     character_rnn: True
                                     clean_prefix_expr: True
                                     clip_grad_norm: 5
                                     command: python main.py --local_rank=1 --exp_name treelstm_50k_numenc --emb_dim 128 --n_dec_layers 6 --n_heads 8 --dropout '0.1' --symmetric --treelstm --character_rnn --optimizer 'adam,lr=0.0001' --batch_size 64 --tasks prim_fwd --reload_data 'prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test' --reload_size 50000 --epoch_size 50000 --max_epoch 50 --exp_id "11625221"
                                     cpu: False
                                     debug: False
                                     debug_slurm: False
                                     dropout: 0.1
                                     dump_path: ./dumped/treelstm_50k_numenc/11625221
                                     emb_dim: 128
                                     env_base_seed: 0
                                     env_name: char_sp
                                     epoch_size: 50000
                                     eval_only: False
                                     eval_verbose: 0
                                     eval_verbose_print: False
                                     exp_id: 11625221
                                     exp_name: treelstm_50k_numenc
                                     export_data: False
                                     fp16: False
                                     global_rank: 1
                                     int_base: 10
                                     is_master: False
                                     is_slurm_job: True
                                     leaf_probs: 0.75,0,0.25,0
                                     local_rank: 1
                                     master_addr: 127.0.0.1
                                     master_port: 29500
                                     max_epoch: 50
                                     max_int: 10000
                                     max_len: 512
                                     max_ops: 10
                                     max_ops_G: 4
                                     multi_gpu: True
                                     multi_node: False
                                     n_coefficients: 0
                                     n_dec_layers: 6
                                     n_enc_layers: 4
                                     n_gpu_per_node: 4
                                     n_heads: 8
                                     n_nodes: 1
                                     n_variables: 1
                                     node_id: 0
                                     num_bit: 10
                                     num_workers: 10
                                     operators: add:2,sub:1
                                     optimizer: adam,lr=0.0001
                                     order: 1
                                     positive: False
                                     precision: 10
                                     reload_checkpoint: 
                                     reload_data: prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test
                                     reload_model: 
                                     reload_size: 50000
                                     rewrite_functions: 
                                     same_nb_ops_per_batch: False
                                     save_periodic: 0
                                     share_inout_emb: True
                                     sinusoidal_embeddings: False
                                     stopping_criterion: 
                                     symmetric: True
                                     tasks: prim_fwd
                                     treelstm: True
                                     treesmu: False
                                     validation_metrics: 
                                     vars: 1
                                     world_size: 4
INFO - 09/20/20 22:42:55 - 0:00:00 - The experiment will be stored in ./dumped/treelstm_50k_numenc/11625221
                                     
INFO - 09/20/20 22:42:55 - 0:00:00 - Running command: python main.py --local_rank=1 --exp_name treelstm_50k_numenc --emb_dim 128 --n_dec_layers 6 --n_heads 8 --dropout '0.1' --symmetric --treelstm --character_rnn --optimizer 'adam,lr=0.0001' --batch_size 64 --tasks prim_fwd --reload_data 'prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test' --reload_size 50000 --epoch_size 50000 --max_epoch 50

WARNING - 09/20/20 22:42:55 - 0:00:00 - Signal handler installed.
dict_items([('add', 2), ('sub', 2), ('mul', 2), ('div', 2), ('pow', 2), ('rac', 2), ('inv', 1), ('pow2', 1), ('pow3', 1), ('pow4', 1), ('pow5', 1), ('sqrt', 1), ('exp', 1), ('ln', 1), ('abs', 1), ('sign', 1), ('sin', 1), ('cos', 1), ('tan', 1), ('cot', 1), ('sec', 1), ('csc', 1), ('asin', 1), ('acos', 1), ('atan', 1), ('acot', 1), ('asec', 1), ('acsc', 1), ('sinh', 1), ('cosh', 1), ('tanh', 1), ('coth', 1), ('sech', 1), ('csch', 1), ('asinh', 1), ('acosh', 1), ('atanh', 1), ('acoth', 1), ('asech', 1), ('acsch', 1), ('derivative', 2), ('f', 1), ('g', 2)])
INFO - 09/20/20 22:42:55 - 0:00:00 - Unary operators: ['inv', 'pow2', 'pow3', 'pow4', 'pow5', 'sqrt', 'exp', 'ln', 'abs', 'sign', 'sin', 'cos', 'tan', 'cot', 'sec', 'csc', 'asin', 'acos', 'atan', 'acot', 'asec', 'acsc', 'sinh', 'cosh', 'tanh', 'coth', 'sech', 'csch', 'asinh', 'acosh', 'atanh', 'acoth', 'asech', 'acsch', 'f']
INFO - 09/20/20 22:42:55 - 0:00:00 - Binary operators: ['add', 'sub', 'mul', 'div', 'pow', 'rac', 'derivative', 'g']
INFO - 09/20/20 22:42:55 - 0:00:00 - words: {'<s>': 0, '</s>': 1, '<pad>': 2, '(': 3, ')': 4, '<SPECIAL_5>': 5, '<SPECIAL_6>': 6, '<SPECIAL_7>': 7, '<SPECIAL_8>': 8, '<SPECIAL_9>': 9, 'pi': 10, 'E': 11, 'x': 12, 'y': 13, 'z': 14, 't': 15, 'a0': 16, 'a1': 17, 'a2': 18, 'a3': 19, 'a4': 20, 'a5': 21, 'a6': 22, 'a7': 23, 'a8': 24, 'a9': 25, 'abs': 26, 'acos': 27, 'acosh': 28, 'acot': 29, 'acoth': 30, 'acsc': 31, 'acsch': 32, 'add': 33, 'asec': 34, 'asech': 35, 'asin': 36, 'asinh': 37, 'atan': 38, 'atanh': 39, 'cos': 40, 'cosh': 41, 'cot': 42, 'coth': 43, 'csc': 44, 'csch': 45, 'derivative': 46, 'div': 47, 'exp': 48, 'f': 49, 'g': 50, 'inv': 51, 'ln': 52, 'mul': 53, 'pow': 54, 'pow2': 55, 'pow3': 56, 'pow4': 57, 'pow5': 58, 'rac': 59, 'sec': 60, 'sech': 61, 'sign': 62, 'sin': 63, 'sinh': 64, 'sqrt': 65, 'sub': 66, 'tan': 67, 'tanh': 68, 'I': 69, 'INT+': 70, 'INT-': 71, 'INT': 72, 'FLOAT': 73, '-': 74, '.': 75, '10^': 76, 'Y': 77, "Y'": 78, "Y''": 79, '0': 80, '1': 81, '2': 82, '3': 83, '4': 84, '5': 85, '6': 86, '7': 87, '8': 88, '9': 89}
INFO - 09/20/20 22:42:55 - 0:00:00 - 20001 possible leaves.
INFO - 09/20/20 22:42:55 - 0:00:00 - Checking expressions in [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 2.1, 3.1, -0.01, -0.1, -0.3, -0.5, -0.7, -0.9, -1.1, -2.1, -3.1]
INFO - 09/20/20 22:42:55 - 0:00:00 - Training tasks: prim_fwd
INFO - 09/20/20 22:42:55 - 0:00:00 - ============ Initialized logger ============
INFO - 09/20/20 22:42:55 - 0:00:00 - accumulate_gradients: 1
                                     amp: -1
                                     attention_dropout: 0
                                     balanced: False
                                     batch_size: 64
                                     beam_early_stopping: True
                                     beam_eval: False
                                     beam_length_penalty: 1
                                     beam_size: 1
                                     character_rnn: True
                                     clean_prefix_expr: True
                                     clip_grad_norm: 5
                                     command: python main.py --local_rank=2 --exp_name treelstm_50k_numenc --emb_dim 128 --n_dec_layers 6 --n_heads 8 --dropout '0.1' --symmetric --treelstm --character_rnn --optimizer 'adam,lr=0.0001' --batch_size 64 --tasks prim_fwd --reload_data 'prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test' --reload_size 50000 --epoch_size 50000 --max_epoch 50 --exp_id "11625221"
                                     cpu: False
                                     debug: False
                                     debug_slurm: False
                                     dropout: 0.1
                                     dump_path: ./dumped/treelstm_50k_numenc/11625221
                                     emb_dim: 128
                                     env_base_seed: 0
                                     env_name: char_sp
                                     epoch_size: 50000
                                     eval_only: False
                                     eval_verbose: 0
                                     eval_verbose_print: False
                                     exp_id: 11625221
                                     exp_name: treelstm_50k_numenc
                                     export_data: False
                                     fp16: False
                                     global_rank: 2
                                     int_base: 10
                                     is_master: False
                                     is_slurm_job: True
                                     leaf_probs: 0.75,0,0.25,0
                                     local_rank: 2
                                     master_addr: 127.0.0.1
                                     master_port: 29500
                                     max_epoch: 50
                                     max_int: 10000
                                     max_len: 512
                                     max_ops: 10
                                     max_ops_G: 4
                                     multi_gpu: True
                                     multi_node: False
                                     n_coefficients: 0
                                     n_dec_layers: 6
                                     n_enc_layers: 4
                                     n_gpu_per_node: 4
                                     n_heads: 8
                                     n_nodes: 1
                                     n_variables: 1
                                     node_id: 0
                                     num_bit: 10
                                     num_workers: 10
                                     operators: add:2,sub:1
                                     optimizer: adam,lr=0.0001
                                     order: 1
                                     positive: False
                                     precision: 10
                                     reload_checkpoint: 
                                     reload_data: prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test
                                     reload_model: 
                                     reload_size: 50000
                                     rewrite_functions: 
                                     same_nb_ops_per_batch: False
                                     save_periodic: 0
                                     share_inout_emb: True
                                     sinusoidal_embeddings: False
                                     stopping_criterion: 
                                     symmetric: True
                                     tasks: prim_fwd
                                     treelstm: True
                                     treesmu: False
                                     validation_metrics: 
                                     vars: 1
                                     world_size: 4
INFO - 09/20/20 22:42:55 - 0:00:00 - The experiment will be stored in ./dumped/treelstm_50k_numenc/11625221
                                     
INFO - 09/20/20 22:42:55 - 0:00:00 - Running command: python main.py --local_rank=2 --exp_name treelstm_50k_numenc --emb_dim 128 --n_dec_layers 6 --n_heads 8 --dropout '0.1' --symmetric --treelstm --character_rnn --optimizer 'adam,lr=0.0001' --batch_size 64 --tasks prim_fwd --reload_data 'prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test' --reload_size 50000 --epoch_size 50000 --max_epoch 50

WARNING - 09/20/20 22:42:55 - 0:00:00 - Signal handler installed.
dict_items([('add', 2), ('sub', 2), ('mul', 2), ('div', 2), ('pow', 2), ('rac', 2), ('inv', 1), ('pow2', 1), ('pow3', 1), ('pow4', 1), ('pow5', 1), ('sqrt', 1), ('exp', 1), ('ln', 1), ('abs', 1), ('sign', 1), ('sin', 1), ('cos', 1), ('tan', 1), ('cot', 1), ('sec', 1), ('csc', 1), ('asin', 1), ('acos', 1), ('atan', 1), ('acot', 1), ('asec', 1), ('acsc', 1), ('sinh', 1), ('cosh', 1), ('tanh', 1), ('coth', 1), ('sech', 1), ('csch', 1), ('asinh', 1), ('acosh', 1), ('atanh', 1), ('acoth', 1), ('asech', 1), ('acsch', 1), ('derivative', 2), ('f', 1), ('g', 2)])
INFO - 09/20/20 22:42:55 - 0:00:00 - Unary operators: ['inv', 'pow2', 'pow3', 'pow4', 'pow5', 'sqrt', 'exp', 'ln', 'abs', 'sign', 'sin', 'cos', 'tan', 'cot', 'sec', 'csc', 'asin', 'acos', 'atan', 'acot', 'asec', 'acsc', 'sinh', 'cosh', 'tanh', 'coth', 'sech', 'csch', 'asinh', 'acosh', 'atanh', 'acoth', 'asech', 'acsch', 'f']
INFO - 09/20/20 22:42:55 - 0:00:00 - Binary operators: ['add', 'sub', 'mul', 'div', 'pow', 'rac', 'derivative', 'g']
INFO - 09/20/20 22:42:55 - 0:00:00 - words: {'<s>': 0, '</s>': 1, '<pad>': 2, '(': 3, ')': 4, '<SPECIAL_5>': 5, '<SPECIAL_6>': 6, '<SPECIAL_7>': 7, '<SPECIAL_8>': 8, '<SPECIAL_9>': 9, 'pi': 10, 'E': 11, 'x': 12, 'y': 13, 'z': 14, 't': 15, 'a0': 16, 'a1': 17, 'a2': 18, 'a3': 19, 'a4': 20, 'a5': 21, 'a6': 22, 'a7': 23, 'a8': 24, 'a9': 25, 'abs': 26, 'acos': 27, 'acosh': 28, 'acot': 29, 'acoth': 30, 'acsc': 31, 'acsch': 32, 'add': 33, 'asec': 34, 'asech': 35, 'asin': 36, 'asinh': 37, 'atan': 38, 'atanh': 39, 'cos': 40, 'cosh': 41, 'cot': 42, 'coth': 43, 'csc': 44, 'csch': 45, 'derivative': 46, 'div': 47, 'exp': 48, 'f': 49, 'g': 50, 'inv': 51, 'ln': 52, 'mul': 53, 'pow': 54, 'pow2': 55, 'pow3': 56, 'pow4': 57, 'pow5': 58, 'rac': 59, 'sec': 60, 'sech': 61, 'sign': 62, 'sin': 63, 'sinh': 64, 'sqrt': 65, 'sub': 66, 'tan': 67, 'tanh': 68, 'I': 69, 'INT+': 70, 'INT-': 71, 'INT': 72, 'FLOAT': 73, '-': 74, '.': 75, '10^': 76, 'Y': 77, "Y'": 78, "Y''": 79, '0': 80, '1': 81, '2': 82, '3': 83, '4': 84, '5': 85, '6': 86, '7': 87, '8': 88, '9': 89}
INFO - 09/20/20 22:42:55 - 0:00:00 - 20001 possible leaves.
INFO - 09/20/20 22:42:55 - 0:00:00 - Checking expressions in [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 2.1, 3.1, -0.01, -0.1, -0.3, -0.5, -0.7, -0.9, -1.1, -2.1, -3.1]
INFO - 09/20/20 22:42:55 - 0:00:00 - Training tasks: prim_fwd
/home/aypan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
/home/aypan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
INFO - 09/20/20 22:42:55 - 0:00:00 - Number of parameters (encoder): 3688832
INFO - 09/20/20 22:42:55 - 0:00:00 - Number of parameters (decoder): 2123610
INFO - 09/20/20 22:42:55 - 0:00:00 - Number of parameters (encoder): 3688832
INFO - 09/20/20 22:42:55 - 0:00:00 - Number of parameters (decoder): 2123610
INFO - 09/20/20 22:42:56 - 0:00:00 - ============ Initialized logger ============
INFO - 09/20/20 22:42:56 - 0:00:00 - ============ Initialized logger ============
INFO - 09/20/20 22:42:56 - 0:00:00 - accumulate_gradients: 1
                                     amp: -1
                                     attention_dropout: 0
                                     balanced: False
                                     batch_size: 64
                                     beam_early_stopping: True
                                     beam_eval: False
                                     beam_length_penalty: 1
                                     beam_size: 1
                                     character_rnn: True
                                     clean_prefix_expr: True
                                     clip_grad_norm: 5
                                     command: python main.py --local_rank=0 --exp_name treelstm_50k_numenc --emb_dim 128 --n_dec_layers 6 --n_heads 8 --dropout '0.1' --symmetric --treelstm --character_rnn --optimizer 'adam,lr=0.0001' --batch_size 64 --tasks prim_fwd --reload_data 'prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test' --reload_size 50000 --epoch_size 50000 --max_epoch 50 --exp_id "11625221"
                                     cpu: False
                                     debug: False
                                     debug_slurm: False
                                     dropout: 0.1
                                     dump_path: ./dumped/treelstm_50k_numenc/11625221
                                     emb_dim: 128
                                     env_base_seed: 0
                                     env_name: char_sp
                                     epoch_size: 50000
                                     eval_only: False
                                     eval_verbose: 0
                                     eval_verbose_print: False
                                     exp_id: 11625221
                                     exp_name: treelstm_50k_numenc
                                     export_data: False
                                     fp16: False
                                     global_rank: 0
                                     int_base: 10
                                     is_master: True
                                     is_slurm_job: True
                                     leaf_probs: 0.75,0,0.25,0
                                     local_rank: 0
                                     master_addr: 127.0.0.1
                                     master_port: 29500
                                     max_epoch: 50
                                     max_int: 10000
                                     max_len: 512
                                     max_ops: 10
                                     max_ops_G: 4
                                     multi_gpu: True
                                     multi_node: False
                                     n_coefficients: 0
                                     n_dec_layers: 6
                                     n_enc_layers: 4
                                     n_gpu_per_node: 4
                                     n_heads: 8
                                     n_nodes: 1
                                     n_variables: 1
                                     node_id: 0
                                     num_bit: 10
                                     num_workers: 10
                                     operators: add:2,sub:1
                                     optimizer: adam,lr=0.0001
                                     order: 1
                                     positive: False
                                     precision: 10
                                     reload_checkpoint: 
                                     reload_data: prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test
                                     reload_model: 
                                     reload_size: 50000
                                     rewrite_functions: 
                                     same_nb_ops_per_batch: False
                                     save_periodic: 0
                                     share_inout_emb: True
                                     sinusoidal_embeddings: False
                                     stopping_criterion: 
                                     symmetric: True
                                     tasks: prim_fwd
                                     treelstm: True
                                     treesmu: False
                                     validation_metrics: 
                                     vars: 1
                                     world_size: 4
INFO - 09/20/20 22:42:56 - 0:00:00 - The experiment will be stored in ./dumped/treelstm_50k_numenc/11625221
                                     
INFO - 09/20/20 22:42:56 - 0:00:00 - Running command: python main.py --local_rank=0 --exp_name treelstm_50k_numenc --emb_dim 128 --n_dec_layers 6 --n_heads 8 --dropout '0.1' --symmetric --treelstm --character_rnn --optimizer 'adam,lr=0.0001' --batch_size 64 --tasks prim_fwd --reload_data 'prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test' --reload_size 50000 --epoch_size 50000 --max_epoch 50

WARNING - 09/20/20 22:42:56 - 0:00:00 - Signal handler installed.
dict_items([('add', 2), ('sub', 2), ('mul', 2), ('div', 2), ('pow', 2), ('rac', 2), ('inv', 1), ('pow2', 1), ('pow3', 1), ('pow4', 1), ('pow5', 1), ('sqrt', 1), ('exp', 1), ('ln', 1), ('abs', 1), ('sign', 1), ('sin', 1), ('cos', 1), ('tan', 1), ('cot', 1), ('sec', 1), ('csc', 1), ('asin', 1), ('acos', 1), ('atan', 1), ('acot', 1), ('asec', 1), ('acsc', 1), ('sinh', 1), ('cosh', 1), ('tanh', 1), ('coth', 1), ('sech', 1), ('csch', 1), ('asinh', 1), ('acosh', 1), ('atanh', 1), ('acoth', 1), ('asech', 1), ('acsch', 1), ('derivative', 2), ('f', 1), ('g', 2)])
INFO - 09/20/20 22:42:56 - 0:00:00 - Unary operators: ['inv', 'pow2', 'pow3', 'pow4', 'pow5', 'sqrt', 'exp', 'ln', 'abs', 'sign', 'sin', 'cos', 'tan', 'cot', 'sec', 'csc', 'asin', 'acos', 'atan', 'acot', 'asec', 'acsc', 'sinh', 'cosh', 'tanh', 'coth', 'sech', 'csch', 'asinh', 'acosh', 'atanh', 'acoth', 'asech', 'acsch', 'f']
INFO - 09/20/20 22:42:56 - 0:00:00 - Binary operators: ['add', 'sub', 'mul', 'div', 'pow', 'rac', 'derivative', 'g']
INFO - 09/20/20 22:42:56 - 0:00:00 - words: {'<s>': 0, '</s>': 1, '<pad>': 2, '(': 3, ')': 4, '<SPECIAL_5>': 5, '<SPECIAL_6>': 6, '<SPECIAL_7>': 7, '<SPECIAL_8>': 8, '<SPECIAL_9>': 9, 'pi': 10, 'E': 11, 'x': 12, 'y': 13, 'z': 14, 't': 15, 'a0': 16, 'a1': 17, 'a2': 18, 'a3': 19, 'a4': 20, 'a5': 21, 'a6': 22, 'a7': 23, 'a8': 24, 'a9': 25, 'abs': 26, 'acos': 27, 'acosh': 28, 'acot': 29, 'acoth': 30, 'acsc': 31, 'acsch': 32, 'add': 33, 'asec': 34, 'asech': 35, 'asin': 36, 'asinh': 37, 'atan': 38, 'atanh': 39, 'cos': 40, 'cosh': 41, 'cot': 42, 'coth': 43, 'csc': 44, 'csch': 45, 'derivative': 46, 'div': 47, 'exp': 48, 'f': 49, 'g': 50, 'inv': 51, 'ln': 52, 'mul': 53, 'pow': 54, 'pow2': 55, 'pow3': 56, 'pow4': 57, 'pow5': 58, 'rac': 59, 'sec': 60, 'sech': 61, 'sign': 62, 'sin': 63, 'sinh': 64, 'sqrt': 65, 'sub': 66, 'tan': 67, 'tanh': 68, 'I': 69, 'INT+': 70, 'INT-': 71, 'INT': 72, 'FLOAT': 73, '-': 74, '.': 75, '10^': 76, 'Y': 77, "Y'": 78, "Y''": 79, '0': 80, '1': 81, '2': 82, '3': 83, '4': 84, '5': 85, '6': 86, '7': 87, '8': 88, '9': 89}
INFO - 09/20/20 22:42:56 - 0:00:00 - 20001 possible leaves.
INFO - 09/20/20 22:42:56 - 0:00:00 - Checking expressions in [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 2.1, 3.1, -0.01, -0.1, -0.3, -0.5, -0.7, -0.9, -1.1, -2.1, -3.1]
INFO - 09/20/20 22:42:56 - 0:00:00 - Training tasks: prim_fwd
/home/aypan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
INFO - 09/20/20 22:42:56 - 0:00:00 - Number of parameters (encoder): 3688832
INFO - 09/20/20 22:42:56 - 0:00:00 - Number of parameters (decoder): 2123610
INFO - 09/20/20 22:42:57 - 0:00:00 - accumulate_gradients: 1
                                     amp: -1
                                     attention_dropout: 0
                                     balanced: False
                                     batch_size: 64
                                     beam_early_stopping: True
                                     beam_eval: False
                                     beam_length_penalty: 1
                                     beam_size: 1
                                     character_rnn: True
                                     clean_prefix_expr: True
                                     clip_grad_norm: 5
                                     command: python main.py --local_rank=3 --exp_name treelstm_50k_numenc --emb_dim 128 --n_dec_layers 6 --n_heads 8 --dropout '0.1' --symmetric --treelstm --character_rnn --optimizer 'adam,lr=0.0001' --batch_size 64 --tasks prim_fwd --reload_data 'prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test' --reload_size 50000 --epoch_size 50000 --max_epoch 50 --exp_id "11625221"
                                     cpu: False
                                     debug: False
                                     debug_slurm: False
                                     dropout: 0.1
                                     dump_path: ./dumped/treelstm_50k_numenc/11625221
                                     emb_dim: 128
                                     env_base_seed: 0
                                     env_name: char_sp
                                     epoch_size: 50000
                                     eval_only: False
                                     eval_verbose: 0
                                     eval_verbose_print: False
                                     exp_id: 11625221
                                     exp_name: treelstm_50k_numenc
                                     export_data: False
                                     fp16: False
                                     global_rank: 3
                                     int_base: 10
                                     is_master: False
                                     is_slurm_job: True
                                     leaf_probs: 0.75,0,0.25,0
                                     local_rank: 3
                                     master_addr: 127.0.0.1
                                     master_port: 29500
                                     max_epoch: 50
                                     max_int: 10000
                                     max_len: 512
                                     max_ops: 10
                                     max_ops_G: 4
                                     multi_gpu: True
                                     multi_node: False
                                     n_coefficients: 0
                                     n_dec_layers: 6
                                     n_enc_layers: 4
                                     n_gpu_per_node: 4
                                     n_heads: 8
                                     n_nodes: 1
                                     n_variables: 1
                                     node_id: 0
                                     num_bit: 10
                                     num_workers: 10
                                     operators: add:2,sub:1
                                     optimizer: adam,lr=0.0001
                                     order: 1
                                     positive: False
                                     precision: 10
                                     reload_checkpoint: 
                                     reload_data: prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test
                                     reload_model: 
                                     reload_size: 50000
                                     rewrite_functions: 
                                     same_nb_ops_per_batch: False
                                     save_periodic: 0
                                     share_inout_emb: True
                                     sinusoidal_embeddings: False
                                     stopping_criterion: 
                                     symmetric: True
                                     tasks: prim_fwd
                                     treelstm: True
                                     treesmu: False
                                     validation_metrics: 
                                     vars: 1
                                     world_size: 4
INFO - 09/20/20 22:42:57 - 0:00:01 - The experiment will be stored in ./dumped/treelstm_50k_numenc/11625221
                                     
INFO - 09/20/20 22:42:57 - 0:00:01 - Running command: python main.py --local_rank=3 --exp_name treelstm_50k_numenc --emb_dim 128 --n_dec_layers 6 --n_heads 8 --dropout '0.1' --symmetric --treelstm --character_rnn --optimizer 'adam,lr=0.0001' --batch_size 64 --tasks prim_fwd --reload_data 'prim_fwd,fwd_small/fwd_small.train,fwd_small/fwd_small.valid,fwd_small/fwd_small.test' --reload_size 50000 --epoch_size 50000 --max_epoch 50

WARNING - 09/20/20 22:42:57 - 0:00:01 - Signal handler installed.
dict_items([('add', 2), ('sub', 2), ('mul', 2), ('div', 2), ('pow', 2), ('rac', 2), ('inv', 1), ('pow2', 1), ('pow3', 1), ('pow4', 1), ('pow5', 1), ('sqrt', 1), ('exp', 1), ('ln', 1), ('abs', 1), ('sign', 1), ('sin', 1), ('cos', 1), ('tan', 1), ('cot', 1), ('sec', 1), ('csc', 1), ('asin', 1), ('acos', 1), ('atan', 1), ('acot', 1), ('asec', 1), ('acsc', 1), ('sinh', 1), ('cosh', 1), ('tanh', 1), ('coth', 1), ('sech', 1), ('csch', 1), ('asinh', 1), ('acosh', 1), ('atanh', 1), ('acoth', 1), ('asech', 1), ('acsch', 1), ('derivative', 2), ('f', 1), ('g', 2)])
INFO - 09/20/20 22:42:57 - 0:00:01 - Unary operators: ['inv', 'pow2', 'pow3', 'pow4', 'pow5', 'sqrt', 'exp', 'ln', 'abs', 'sign', 'sin', 'cos', 'tan', 'cot', 'sec', 'csc', 'asin', 'acos', 'atan', 'acot', 'asec', 'acsc', 'sinh', 'cosh', 'tanh', 'coth', 'sech', 'csch', 'asinh', 'acosh', 'atanh', 'acoth', 'asech', 'acsch', 'f']
INFO - 09/20/20 22:42:57 - 0:00:01 - Binary operators: ['add', 'sub', 'mul', 'div', 'pow', 'rac', 'derivative', 'g']
INFO - 09/20/20 22:42:57 - 0:00:01 - words: {'<s>': 0, '</s>': 1, '<pad>': 2, '(': 3, ')': 4, '<SPECIAL_5>': 5, '<SPECIAL_6>': 6, '<SPECIAL_7>': 7, '<SPECIAL_8>': 8, '<SPECIAL_9>': 9, 'pi': 10, 'E': 11, 'x': 12, 'y': 13, 'z': 14, 't': 15, 'a0': 16, 'a1': 17, 'a2': 18, 'a3': 19, 'a4': 20, 'a5': 21, 'a6': 22, 'a7': 23, 'a8': 24, 'a9': 25, 'abs': 26, 'acos': 27, 'acosh': 28, 'acot': 29, 'acoth': 30, 'acsc': 31, 'acsch': 32, 'add': 33, 'asec': 34, 'asech': 35, 'asin': 36, 'asinh': 37, 'atan': 38, 'atanh': 39, 'cos': 40, 'cosh': 41, 'cot': 42, 'coth': 43, 'csc': 44, 'csch': 45, 'derivative': 46, 'div': 47, 'exp': 48, 'f': 49, 'g': 50, 'inv': 51, 'ln': 52, 'mul': 53, 'pow': 54, 'pow2': 55, 'pow3': 56, 'pow4': 57, 'pow5': 58, 'rac': 59, 'sec': 60, 'sech': 61, 'sign': 62, 'sin': 63, 'sinh': 64, 'sqrt': 65, 'sub': 66, 'tan': 67, 'tanh': 68, 'I': 69, 'INT+': 70, 'INT-': 71, 'INT': 72, 'FLOAT': 73, '-': 74, '.': 75, '10^': 76, 'Y': 77, "Y'": 78, "Y''": 79, '0': 80, '1': 81, '2': 82, '3': 83, '4': 84, '5': 85, '6': 86, '7': 87, '8': 88, '9': 89}
INFO - 09/20/20 22:42:57 - 0:00:01 - 20001 possible leaves.
INFO - 09/20/20 22:42:57 - 0:00:01 - Checking expressions in [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 2.1, 3.1, -0.01, -0.1, -0.3, -0.5, -0.7, -0.9, -1.1, -2.1, -3.1]
INFO - 09/20/20 22:42:57 - 0:00:01 - Training tasks: prim_fwd
/home/aypan/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
INFO - 09/20/20 22:42:58 - 0:00:01 - Number of parameters (encoder): 3688832
INFO - 09/20/20 22:42:58 - 0:00:01 - Number of parameters (decoder): 2123610
INFO - 09/20/20 22:43:01 - 0:00:06 - Found 570 parameters in model.
INFO - 09/20/20 22:43:01 - 0:00:06 - Using nn.parallel.DistributedDataParallel ...
INFO - 09/20/20 22:43:01 - 0:00:06 - Found 570 parameters in model.
INFO - 09/20/20 22:43:01 - 0:00:06 - Using nn.parallel.DistributedDataParallel ...
INFO - 09/20/20 22:43:02 - 0:00:06 - Found 570 parameters in model.
INFO - 09/20/20 22:43:02 - 0:00:06 - Using nn.parallel.DistributedDataParallel ...
INFO - 09/20/20 22:43:04 - 0:00:08 - Found 570 parameters in model.
INFO - 09/20/20 22:43:04 - 0:00:08 - Using nn.parallel.DistributedDataParallel ...
INFO - 09/20/20 22:43:04 - 0:00:08 - Optimizers: model
INFO - 09/20/20 22:43:04 - 0:00:08 - Optimizers: model
INFO - 09/20/20 22:43:04 - 0:00:08 - Creating train iterator for prim_fwd ...
['abs', 'acos', 'acosh', 'acot', 'acoth', 'acsc', 'acsch', 'add', 'asec', 'asech', 'asin', 'asinh', 'atan', 'atanh', 'cos', 'cosh', 'cot', 'coth', 'csc', 'csch', 'derivative', 'div', 'exp', 'f', 'g', 'inv', 'ln', 'mul', 'pow', 'pow2', 'pow3', 'pow4', 'pow5', 'rac', 'sec', 'sech', 'sign', 'sin', 'sinh', 'sqrt', 'sub', 'tan', 'tanh']
INFO - 09/20/20 22:43:04 - 0:00:08 - Creating train iterator for prim_fwd ...
INFO - 09/20/20 22:43:04 - 0:00:08 - Loading data from fwd_small/fwd_small.train ...
['abs', 'acos', 'acosh', 'acot', 'acoth', 'acsc', 'acsch', 'add', 'asec', 'asech', 'asin', 'asinh', 'atan', 'atanh', 'cos', 'cosh', 'cot', 'coth', 'csc', 'csch', 'derivative', 'div', 'exp', 'f', 'g', 'inv', 'ln', 'mul', 'pow', 'pow2', 'pow3', 'pow4', 'pow5', 'rac', 'sec', 'sech', 'sign', 'sin', 'sinh', 'sqrt', 'sub', 'tan', 'tanh']
INFO - 09/20/20 22:43:04 - 0:00:08 - Loading data from fwd_small/fwd_small.train ...
INFO - 09/20/20 22:43:04 - 0:00:09 - Optimizers: model
INFO - 09/20/20 22:43:04 - 0:00:09 - Optimizers: model
INFO - 09/20/20 22:43:04 - 0:00:09 - Creating train iterator for prim_fwd ...
['abs', 'acos', 'acosh', 'acot', 'acoth', 'acsc', 'acsch', 'add', 'asec', 'asech', 'asin', 'asinh', 'atan', 'atanh', 'cos', 'cosh', 'cot', 'coth', 'csc', 'csch', 'derivative', 'div', 'exp', 'f', 'g', 'inv', 'ln', 'mul', 'pow', 'pow2', 'pow3', 'pow4', 'pow5', 'rac', 'sec', 'sech', 'sign', 'sin', 'sinh', 'sqrt', 'sub', 'tan', 'tanh']INFO - 09/20/20 22:43:04 - 0:00:08 - Loaded 12500 equations from the disk.
INFO - 09/20/20 22:43:04 - 0:00:08 - Loaded 12500 equations from the disk.

INFO - 09/20/20 22:43:04 - 0:00:09 - Creating train iterator for prim_fwd ...
['abs', 'acos', 'acosh', 'acot', 'acoth', 'acsc', 'acsch', 'add', 'asec', 'asech', 'asin', 'asinh', 'atan', 'atanh', 'cos', 'cosh', 'cot', 'coth', 'csc', 'csch', 'derivative', 'div', 'exp', 'f', 'g', 'inv', 'ln', 'mul', 'pow', 'pow2', 'pow3', 'pow4', 'pow5', 'rac', 'sec', 'sech', 'sign', 'sin', 'sinh', 'sqrt', 'sub', 'tan', 'tanh']
INFO - 09/20/20 22:43:04 - 0:00:09 - Loading data from fwd_small/fwd_small.train ...
INFO - 09/20/20 22:43:04 - 0:00:09 - Loading data from fwd_small/fwd_small.train ...
INFO - 09/20/20 22:43:05 - 0:00:09 - Loaded 12500 equations from the disk.
INFO - 09/20/20 22:43:05 - 0:00:09 - Loaded 12500 equations from the disk.
INFO - 09/20/20 22:43:05 - 0:00:09 - ============ Starting epoch 0 ... ============
INFO - 09/20/20 22:43:05 - 0:00:09 - ============ Starting epoch 0 ... ============
INFO - 09/20/20 22:43:05 - 0:00:09 - Initialized random generator for worker 0, with seed [0, 0, 0] (base seed=0).
INFO - 09/20/20 22:43:05 - 0:00:09 - Initialized random generator for worker 0, with seed [0, 3, 0] (base seed=0).
INFO - 09/20/20 22:43:05 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 09/20/20 22:43:05 - 0:00:10 - ============ Starting epoch 0 ... ============
INFO - 09/20/20 22:43:05 - 0:00:10 - Initialized random generator for worker 0, with seed [0, 1, 0] (base seed=0).
INFO - 09/20/20 22:43:05 - 0:00:10 - Initialized random generator for worker 0, with seed [0, 2, 0] (base seed=0).
RNN emb: 0.09860825538635254
RNN emb: 0.09573698043823242
RNN emb: 0.12121248245239258
RNN emb: 0.12997865676879883
Forward: 0.7968730926513672
Replace emb: 0.07988500595092773
Forward: 0.9201600551605225
Replace emb: 0.09389495849609375
Forward: 1.0047218799591064
Replace emb: 0.08654308319091797
Forward: 1.0349466800689697
Replace emb: 0.10000824928283691
/opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
/opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
/opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
/opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
RNN emb: 0.001783609390258789
RNN emb: 0.027273178100585938
RNN emb: 0.02864241600036621
RNN emb: 0.005126237869262695
Forward: 0.648510217666626
Forward: 0.6540014743804932
Replace emb: 0.039873361587524414
Replace emb: 0.041826486587524414
Forward: 0.7177164554595947
Replace emb: 0.006309986114501953
Forward: 0.7277145385742188
Replace emb: 0.018927574157714844
RNN emb: 0.02144169807434082
RNN emb: 0.021315574645996094
RNN emb: 0.04175877571105957
RNN emb: 0.02097940444946289
Forward: 0.624053955078125
Replace emb: 0.021228551864624023
Forward: 0.6654574871063232
Forward: 0.6771867275238037
Replace emb: 0.02629375457763672
Replace emb: 0.03570723533630371
Forward: 0.7464950084686279
Replace emb: 0.014548301696777344
RNN emb: 0.03367805480957031
RNN emb: 0.028530597686767578
RNN emb: 0.02840137481689453
RNN emb: 0.008264303207397461
Forward: 0.5530185699462891
Forward: 0.5937497615814209
Replace emb: 0.035944461822509766
Replace emb: 0.0647735595703125
Forward: 0.6698675155639648
Replace emb: 0.03686666488647461
Forward: 0.7822825908660889
Replace emb: 0.015593528747558594
RNN emb: 0.05785012245178223
RNN emb: 0.037207603454589844
RNN emb: 0.027728796005249023
RNN emb: 0.008306264877319336
Forward: 0.6523647308349609
Forward: 0.7023928165435791
Forward: 0.7511141300201416
Replace emb: 0.024022579193115234
Replace emb: 0.025636911392211914
Replace emb: 0.022669553756713867
Forward: 0.732947587966919
Replace emb: 0.09110832214355469
RNN emb: 0.0012094974517822266
RNN emb: 0.0265350341796875
RNN emb: 0.0012164115905761719
RNN emb: 0.008287668228149414
Forward: 0.6032383441925049
Forward: 0.6421165466308594
Replace emb: 0.0531153678894043
Replace emb: 0.03414130210876465
Forward: 0.7917273044586182
Replace emb: 0.03251194953918457
Forward: 0.7318058013916016
Replace emb: 0.03661227226257324
RNN emb: 0.02368307113647461
RNN emb: 0.02741861343383789
RNN emb: 0.027993440628051758
RNN emb: 0.011844635009765625
Forward: 0.6386909484863281
Replace emb: 0.04382944107055664
Forward: 0.6826157569885254
Forward: 0.6863276958465576
Forward: 0.7231135368347168
Replace emb: 0.03915214538574219
Replace emb: 0.03808331489562988
Replace emb: 0.026923179626464844
RNN emb: 0.0012428760528564453
RNN emb: 0.015352487564086914
RNN emb: 0.0012056827545166016
RNN emb: 0.0012161731719970703
Forward: 0.6778569221496582
Replace emb: 0.04775547981262207
Forward: 0.6533751487731934
Replace emb: 0.03336334228515625
Forward: 0.7101616859436035
Replace emb: 0.0061337947845458984
Forward: 0.8297634124755859
Replace emb: 0.031150102615356445
RNN emb: 0.020177602767944336
RNN emb: 0.027400732040405273
RNN emb: 0.00835108757019043
RNN emb: 0.0011141300201416016
Forward: 0.6986768245697021
Replace emb: 0.023560047149658203
Forward: 0.7104640007019043
Replace emb: 0.005442619323730469
Forward: 0.7266433238983154
Forward: 0.7016880512237549
Replace emb: 0.02739405632019043
Replace emb: 0.02404928207397461
RNN emb: 0.0234072208404541
RNN emb: 0.019524097442626953
RNN emb: 0.0011277198791503906
RNN emb: 0.001752614974975586
Forward: 0.5975441932678223
Replace emb: 0.061389923095703125
Forward: 0.676436185836792
Replace emb: 0.017163753509521484
Forward: 0.6927673816680908
Replace emb: 0.013583898544311523
Forward: 0.7708992958068848
Replace emb: 0.01994490623474121
RNN emb: 0.029728174209594727
RNN emb: 0.0011739730834960938
RNN emb: 0.012280941009521484
RNN emb: 0.001291036605834961
Forward: 0.6611545085906982
Replace emb: 0.02915787696838379
Forward: 0.6705598831176758
Replace emb: 0.006725311279296875
Forward: 0.7035079002380371
Forward: 0.7254633903503418
Replace emb: 0.035248756408691406
Replace emb: 0.03220391273498535
RNN emb: 0.0010387897491455078
RNN emb: 0.0010836124420166016
RNN emb: 0.008281469345092773
RNN emb: 0.0011749267578125
Forward: 0.6326887607574463
Forward: 0.6451771259307861
Replace emb: 0.027585983276367188
Forward: 0.6628100872039795
Replace emb: 0.020995378494262695
Forward: 0.7014777660369873
Replace emb: 0.03017878532409668
Replace emb: 0.0283050537109375
RNN emb: 0.0011494159698486328
RNN emb: 0.03170013427734375
RNN emb: 0.008311271667480469
RNN emb: 0.001161336898803711
Forward: 0.5696926116943359
Forward: 0.592843770980835
Replace emb: 0.05326557159423828
Forward: 0.6554889678955078
Replace emb: 0.057739973068237305
Replace emb: 0.019284725189208984
Forward: 0.6993863582611084
Replace emb: 0.015841245651245117
RNN emb: 0.0010402202606201172
RNN emb: 0.029909133911132812
RNN emb: 0.008257150650024414
RNN emb: 0.0010156631469726562
Forward: 0.635636568069458
Replace emb: 0.031090974807739258
Forward: 0.682809591293335
Forward: 0.6520078182220459
Replace emb: 0.019662141799926758
Replace emb: 0.020723342895507812
Forward: 0.7259886264801025
Replace emb: 0.017046689987182617
RNN emb: 0.0011196136474609375
RNN emb: 0.0011565685272216797
RNN emb: 0.0010333061218261719
RNN emb: 0.00831913948059082
Forward: 0.637711763381958
Replace emb: 0.024251937866210938
Forward: 0.7277846336364746
Replace emb: 0.022791385650634766
Forward: 0.6951637268066406
Replace emb: 0.029011964797973633
Forward: 0.7192645072937012
Replace emb: 0.0589449405670166
RNN emb: 0.0010349750518798828
RNN emb: 0.028058767318725586
RNN emb: 0.0258331298828125
RNN emb: 0.01869368553161621
Forward: 0.6176245212554932
Forward: 0.6592576503753662
Replace emb: 0.029728174209594727
Replace emb: 0.026744842529296875
Forward: 0.7335925102233887
Replace emb: 0.021444082260131836
Forward: 0.8112339973449707
Replace emb: 0.026016712188720703
RNN emb: 0.0011446475982666016
RNN emb: 0.027753591537475586
RNN emb: 0.0011277198791503906
RNN emb: 0.008250951766967773
Forward: 0.5852189064025879
Replace emb: 0.05537772178649902
Forward: 0.6682901382446289
Replace emb: 0.017373085021972656
Forward: 0.688870906829834
Replace emb: 0.006224632263183594
Forward: 0.7331066131591797
Replace emb: 0.03977680206298828
RNN emb: 0.023164033889770508
RNN emb: 0.025046586990356445
RNN emb: 0.0010993480682373047
RNN emb: 0.011798620223999023
Forward: 0.6121723651885986
Forward: 0.6441733837127686
Replace emb: 0.034552574157714844
Replace emb: 0.026453018188476562
Forward: 0.6568586826324463
Replace emb: 0.02170419692993164
Forward: 0.7267274856567383
Replace emb: 0.02393031120300293
RNN emb: 0.0010039806365966797
RNN emb: 0.029052019119262695
RNN emb: 0.02920365333557129
RNN emb: 0.010270833969116211
Forward: 0.5585892200469971
Replace emb: 0.060587167739868164
Forward: 0.6798090934753418
Forward: 0.696702241897583
Forward: 0.6853055953979492
Replace emb: 0.02800607681274414
Replace emb: 0.021942615509033203
Replace emb: 0.028778791427612305
RNN emb: 0.028496980667114258
RNN emb: 0.028177499771118164
RNN emb: 0.0010447502136230469
RNN emb: 0.008247852325439453
Forward: 0.6617252826690674
Forward: 0.6412758827209473
Forward: 0.6860020160675049
Replace emb: 0.03873181343078613
Forward: 0.7191767692565918
Replace emb: 0.029911279678344727
Replace emb: 0.02649378776550293
Replace emb: 0.022699594497680664
INFO - 09/20/20 22:43:43 - 0:00:48 -      20 -   32.83 equations/s -  1303.95 words/s - PRIM-FWD:  4.0076 - model LR: 1.0000e-04
INFO - 09/20/20 22:43:43 - 0:00:47 -      20 -   32.70 equations/s -  1309.85 words/s - PRIM-FWD:  4.0142 - model LR: 1.0000e-04
INFO - 09/20/20 22:43:43 - 0:00:48 -      20 -   32.83 equations/s -  1328.27 words/s - PRIM-FWD:  3.9977 - model LR: 1.0000e-04
INFO - 09/20/20 22:43:43 - 0:00:47 -      20 -   32.67 equations/s -  1286.10 words/s - PRIM-FWD:  4.0003 - model LR: 1.0000e-04
RNN emb: 0.0011837482452392578
RNN emb: 0.023612022399902344
RNN emb: 0.018247365951538086
RNN emb: 0.0012469291687011719
Forward: 0.5202267169952393
Forward: 0.5815389156341553
Replace emb: 0.06357383728027344
Replace emb: 0.06256556510925293
Forward: 0.6768667697906494
Replace emb: 0.021997451782226562
Forward: 0.7924294471740723
Replace emb: 0.020703554153442383
RNN emb: 0.0010726451873779297
RNN emb: 0.031087636947631836
RNN emb: 0.0011475086212158203
RNN emb: 0.008280277252197266
Forward: 0.6262922286987305
Replace emb: 0.03559088706970215
Forward: 0.6695075035095215
Forward: 0.7008001804351807
Replace emb: 0.03275752067565918
Replace emb: 0.029371023178100586
Forward: 0.7209782600402832
Replace emb: 0.024932146072387695
RNN emb: 0.017174959182739258
RNN emb: 0.001012563705444336
RNN emb: 0.0011126995086669922
RNN emb: 0.00827646255493164
Forward: 0.6136870384216309
Replace emb: 0.015624046325683594
Forward: 0.6903846263885498
Forward: 0.7206697463989258
Replace emb: 0.021446943283081055
Replace emb: 0.01935720443725586
Forward: 0.7442679405212402
Replace emb: 0.024933338165283203
RNN emb: 0.0012173652648925781
RNN emb: 0.0012235641479492188
RNN emb: 0.02737569808959961
RNN emb: 0.008243083953857422
Forward: 0.6617786884307861
Forward: 0.6742720603942871
Forward: 0.6993663311004639
Replace emb: 0.03616666793823242
Forward: 0.7150073051452637
Replace emb: 0.028208494186401367
Replace emb: 0.02228093147277832
Replace emb: 0.030680179595947266
RNN emb: 0.0010743141174316406
RNN emb: 0.0012042522430419922
RNN emb: 0.02882695198059082
RNN emb: 0.008301258087158203
Forward: 0.6447577476501465
Replace emb: 0.02656722068786621
Forward: 0.6948764324188232
Forward: 0.7292561531066895
Replace emb: 0.022144794464111328
Replace emb: 0.03024578094482422
Forward: 0.7381410598754883
Replace emb: 0.013626337051391602
RNN emb: 0.0010166168212890625
RNN emb: 0.008550643920898438
RNN emb: 0.02514171600341797
RNN emb: 0.01185750961303711
Forward: 0.6528952121734619
Forward: 0.7048487663269043
Replace emb: 0.022799968719482422
Forward: 0.6582639217376709
Replace emb: 0.01782512664794922
Replace emb: 0.040738821029663086
Forward: 0.7140445709228516
Replace emb: 0.016288280487060547
RNN emb: 0.026106595993041992
RNN emb: 0.0010499954223632812
RNN emb: 0.026576757431030273
RNN emb: 0.009330272674560547
Forward: 0.6069703102111816
Forward: 0.6222600936889648
Replace emb: 0.02880072593688965
Replace emb: 0.04074668884277344
Forward: 0.6502163410186768
Replace emb: 0.02718806266784668
Forward: 0.7900118827819824
Replace emb: 0.029903650283813477
RNN emb: RNN emb: 0.0010695457458496094
RNN emb: 0.001024484634399414
0.001085042953491211
RNN emb: 0.011828899383544922
Forward: 0.6369099617004395
Forward: 0.6519343852996826
Replace emb: 0.042551517486572266
Replace emb: 0.02320384979248047
Forward: 0.699052095413208
Replace emb: 0.028280973434448242
Forward: 0.7871913909912109
Replace emb: 0.019063234329223633
RNN emb: 0.0010743141174316406
RNN emb: 0.0213315486907959
RNN emb: 0.027553558349609375
RNN emb: 0.008303642272949219
Forward: 0.6713128089904785
Forward: 0.6848101615905762
Forward: 0.7022175788879395
Replace emb: 0.017269372940063477
Replace emb: 0.017037630081176758
Replace emb: 0.017113447189331055
Forward: 0.7915921211242676
Replace emb: 0.00701594352722168
RNN emb:RNN emb: 0.0010561943054199219
 0.0010251998901367188
RNN emb: 0.001012563705444336
RNN emb: 0.008269309997558594
Forward: 0.6244156360626221
Forward: 0.6545209884643555
Replace emb: 0.012324810028076172
Replace emb: 0.042661190032958984
Forward: 0.6544935703277588
Forward: 0.6953816413879395
Replace emb: 0.022550106048583984
Replace emb: 0.021926403045654297
RNN emb: 0.0010581016540527344
RNN emb: 0.0010268688201904297
RNN emb: 0.0010404586791992188
RNN emb: 0.010251283645629883
Forward: 0.6798999309539795
Forward: 0.6842823028564453
Forward: 0.6722846031188965
Replace emb: 0.026752233505249023
Replace emb: 0.0204923152923584
Replace emb: 0.018799781799316406
Forward: 0.6950926780700684
Replace emb: 0.024421215057373047
RNN emb: 0.001008749008178711
RNN emb: 0.023366928100585938
RNN emb: 0.005185365676879883
RNN emb: 0.024311065673828125
Forward: 0.6358082294464111
Forward: 0.6575698852539062
Replace emb: 0.02651381492614746
Replace emb: 0.02904796600341797
Forward: 0.704448938369751
Forward: 0.7238955497741699
Replace emb: 0.03284287452697754
Replace emb: 0.03113412857055664
RNN emb: 0.0011599063873291016
RNN emb: 0.024669408798217773
RNN emb: 0.0010902881622314453
RNN emb: 0.013242721557617188
Forward: 0.5856659412384033
Forward: 0.599578857421875
Replace emb: 0.05598783493041992
Replace emb: 0.049581289291381836
Forward: 0.7328321933746338
Replace emb: 0.0062601566314697266
Forward: 0.7702865600585938
Replace emb: 0.028913259506225586
RNN emb: 0.024094581604003906
RNN emb: 0.0010886192321777344
RNN emb: 0.03226494789123535
RNN emb: 0.009256601333618164
Forward: 0.6414365768432617
Replace emb: 0.04660534858703613
Forward: 0.6823360919952393
Forward: 0.6970040798187256
Replace emb: 0.01795196533203125
Replace emb: 0.031128883361816406
Forward: 0.7321789264678955
Replace emb: 0.021859169006347656
RNN emb: 0.02078700065612793
RNN emb: 0.01808023452758789
RNN emb: 0.023467540740966797
RNN emb: 0.023910999298095703
Forward: 0.7261652946472168
Forward: 0.7599925994873047
Forward: 0.7588145732879639
Replace emb: 0.062494754791259766
Replace emb: 0.08930397033691406
Replace emb: 0.06542491912841797
Forward: 0.9845492839813232
Replace emb: 0.14685773849487305
RNN emb: 0.026468515396118164
RNN emb: 0.001252889633178711
RNN emb: 0.02356743812561035
RNN emb: 0.011339426040649414
Forward: 0.6078360080718994
Forward: 0.59987473487854
Forward: 0.6453845500946045
Replace emb: 0.041966915130615234
Replace emb: 0.07068347930908203
Replace emb: 0.02077627182006836
Forward: 0.7222363948822021
Replace emb: 0.02152109146118164
RNN emb: 0.001058340072631836
RNN emb: 0.03014397621154785
RNN emb: 0.011250019073486328
RNN emb: 0.005035400390625
Forward: 0.6018221378326416
Forward: 0.595604419708252
Replace emb: 0.05179452896118164
Replace emb: 0.048006296157836914
Forward: 0.6503853797912598
Replace emb: 0.028104305267333984
Forward: 0.8108038902282715
Replace emb: 0.04234147071838379
RNN emb: 0.0010805130004882812
RNN emb: 0.0010094642639160156
RNN emb: 0.0012044906616210938
RNN emb: 0.012816667556762695
Forward: 0.6331503391265869
Forward: 0.6343486309051514
Forward: 0.6294896602630615
Replace emb: 0.03812694549560547
Forward: 0.6679511070251465
Replace emb: 0.040728092193603516
Replace emb: 0.047844886779785156
Replace emb: 0.03407692909240723
RNN emb: 0.0010933876037597656
RNN emb: 0.0011267662048339844
RNN emb: 0.027571678161621094
RNN emb: 0.008279561996459961
Forward: 0.5583932399749756
Replace emb: 0.061895132064819336
Forward: 0.6567213535308838
Replace emb: 0.029368162155151367
Forward: 0.6994352340698242
Forward: 0.7013812065124512
Replace emb: 0.04009675979614258
Replace emb: 0.04514789581298828
RNN emb: 0.031197309494018555
RNN emb: 0.031092405319213867
RNN emb: 0.02122974395751953
RNN emb: 0.008306741714477539
Forward: 0.6230087280273438
Forward: 0.6412739753723145
Replace emb: 0.04101443290710449
Replace emb: 0.04628109931945801
Forward: 0.6806640625
Replace emb: 0.017684459686279297
Forward: 0.713883638381958
Replace emb: 0.027935028076171875
INFO - 09/20/20 22:44:21 - 0:01:25 -      40 -   33.89 equations/s -  1348.89 words/s - PRIM-FWD:  2.8047 - model LR: 1.0000e-04
INFO - 09/20/20 22:44:21 - 0:01:25 -      40 -   33.85 equations/s -  1350.98 words/s - PRIM-FWD:  2.8217 - model LR: 1.0000e-04
INFO - 09/20/20 22:44:21 - 0:01:26 -      40 -   33.85 equations/s -  1374.84 words/s - PRIM-FWD:  2.8100 - model LR: 1.0000e-04
INFO - 09/20/20 22:44:21 - 0:01:26 -      40 -   33.84 equations/s -  1305.60 words/s - PRIM-FWD:  2.7891 - model LR: 1.0000e-04
RNN emb: 0.0011870861053466797
RNN emb: 0.0010464191436767578
RNN emb: 0.015268325805664062
RNN emb: 0.0013108253479003906
Forward: 0.6302609443664551
Forward: 0.6541182994842529
Forward: 0.6063582897186279
Forward: 0.6617419719696045
Replace emb: 0.03991889953613281
Replace emb: 0.04954886436462402
Replace emb: 0.037491798400878906
Replace emb: 0.031760454177856445
RNN emb: 0.0011098384857177734
RNN emb: 0.0011792182922363281
RNN emb: 0.010243415832519531
RNN emb: 0.02153778076171875
Forward: 0.5878450870513916
Replace emb: 0.036164045333862305
Forward: 0.6716890335083008
Forward: 0.6695480346679688
Replace emb: 0.011419296264648438
Replace emb: 0.028289794921875
Forward: 0.7304260730743408
Replace emb: 0.028931856155395508
RNN emb: 0.0010628700256347656
RNN emb: 0.02808856964111328
RNN emb: 0.001018524169921875
RNN emb: 0.011823415756225586
Forward: 0.662900447845459
Forward: 0.6837575435638428
Forward: 0.6526830196380615
Forward: 0.6882367134094238
Replace emb: 0.005190372467041016
Replace emb: 0.03236079216003418
Replace emb: 0.0232083797454834
Replace emb: 0.025017261505126953
RNN emb: 0.0010573863983154297
RNN emb: 0.0010461807250976562
RNN emb: 0.00989532470703125
RNN emb: 0.006441593170166016
Forward: 0.6662678718566895
Forward: 0.6429131031036377
Forward: 0.6750385761260986
Replace emb: 0.028586149215698242
Replace emb: 0.024660825729370117
Replace emb: 0.03954482078552246
Forward: 0.774310827255249
Replace emb: 0.03793525695800781
RNN emb: 0.0010461807250976562
RNN emb: 0.0009984970092773438
RNN emb: 0.0336298942565918
RNN emb: 0.014225244522094727
Forward: 0.6570026874542236
Replace emb: 0.02915644645690918
Forward: 0.7050497531890869
Forward: 0.7329864501953125
Replace emb: 0.020198583602905273
Replace emb: 0.0328516960144043
Forward: 0.7721471786499023
Replace emb: 0.02397465705871582
RNN emb: 0.0011472702026367188
RNN emb: 0.027526378631591797
RNN emb: 0.025660037994384766
RNN emb: 0.01829981803894043
Forward: 0.6020467281341553
Replace emb: 0.04818987846374512
Forward: 0.6749141216278076
Replace emb: 0.02200460433959961
Forward: 0.7218728065490723
Forward: 0.7093856334686279
Replace emb: 0.026448726654052734
Replace emb: 0.027643918991088867
RNN emb: 0.0010089874267578125
RNN emb: 0.02048325538635254
RNN emb: 0.03728008270263672
RNN emb: 0.019268274307250977
Forward: 0.6352975368499756
Replace emb: 0.02366924285888672
Forward: 0.6585977077484131
Forward: 0.6853303909301758
Replace emb: 0.01764965057373047
Replace emb: 0.025995731353759766
Forward: 0.7512271404266357
Replace emb: 0.020581483840942383
RNN emb: 0.0009996891021728516
RNN emb: 0.025109291076660156
RNN emb: 0.0010371208190917969
RNN emb: 0.009319305419921875
Forward: 0.5321552753448486
Replace emb: 0.03371787071228027
Forward: 0.6664652824401855
Forward: 0.6857800483703613
Replace emb: 0.0212705135345459
Replace emb: 0.030412673950195312
Forward: 0.729386568069458
Replace emb: 0.0309298038482666
RNN emb: 0.0011434555053710938
RNN emb: 0.030694961547851562
RNN emb: 0.0011110305786132812
RNN emb: 0.015297174453735352
Forward: 0.659583568572998
Forward: 0.6603350639343262
Replace emb: 0.028549909591674805
Replace emb: 0.022693634033203125
Forward: 0.7108232975006104
Replace emb: 0.015325069427490234
Forward: 0.8095149993896484
Replace emb: 0.024290084838867188
RNN emb: 0.000997781753540039
RNN emb: 0.026058435440063477
RNN emb: 0.02462601661682129
RNN emb: 0.008248090744018555
Forward: 0.6338808536529541
Replace emb: 0.0428314208984375
Forward: 0.7245705127716064
Forward: 0.7178592681884766
Replace emb: 0.036407470703125
Replace emb: 0.027771711349487305
Forward: 0.7653384208679199
Replace emb: 0.041880130767822266
RNN emb: 0.0010311603546142578
RNN emb: 0.030141115188598633
RNN emb: 0.03455352783203125
RNN emb: 0.01384592056274414
slurmstepd: error: *** JOB 11625221 ON hpc-25-17 CANCELLED AT 2020-09-20T22:44:40 ***
