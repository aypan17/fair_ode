SLURM job: True
0 - SLURM_JOB_ID: 10991711
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 21719
SLURM job: True
0 - SLURM_JOB_ID: 10991711
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 21719
SLURM job: True
0 - SLURM_JOB_ID: 10991711
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 21719
SLURM job: True
0 - SLURM_JOB_ID: 10991711
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 21719
0 - Master address: 127.0.0.1
0 - Master port   : 29500
1 - Number of nodes: 1
1 - Node ID									   : 0
1 - Local rank								   : 1
1 - Global rank    : 1
1 - World size								   : 4
1 - GPUs per node  : 4
1 - Master									   : False
1 - Multi-node								   : False
1 - Multi-GPU								   : True
1 - Hostname								   : hpc-25-17.cm.cluster
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected
Traceback (most recent call last):
  File "main.py", line 242, in <module>
0 - Master address: 127.0.0.1
0 - Master port   : 29500
0 - Number of nodes: 1
0 - Node ID									   : 0
0 - Local rank								   : 0
0 - Global rank    : 0
0 - World size								   : 4
0 - GPUs per node  : 4
0 - Master									   : True
0 - Multi-node								   : False
0 - Multi-GPU								   : True
0 - Hostname								   : hpc-25-17.cm.cluster
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected
Traceback (most recent call last):
  File "main.py", line 242, in <module>
    main(params)
  File "main.py", line 165, in main
    main(params)
  File "main.py", line 165, in main
    init_distributed_mode(params)
  File "/central/home/aypan/enc_dec/src/slurm.py", line 155, in init_distributed_mode
    init_distributed_mode(params)
  File "/central/home/aypan/enc_dec/src/slurm.py", line 155, in init_distributed_mode
    torch.cuda.set_device(params.local_rank)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 245, in set_device
    torch.cuda.set_device(params.local_rank)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 245, in set_device
    torch._C._cuda_setDevice(device)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 153, in _lazy_init
    torch._C._cuda_setDevice(device)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 153, in _lazy_init
    torch._C._cuda_init()
RuntimeError: cuda runtime error (100) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp:47
    torch._C._cuda_init()
RuntimeError: cuda runtime error (100) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp:47
0 - Master address: 127.0.0.1
0 - Master port   : 29500
2 - Number of nodes: 1
2 - Node ID									   : 0
2 - Local rank								   : 2
2 - Global rank    : 2
2 - World size								   : 4
2 - GPUs per node  : 4
2 - Master									   : False
2 - Multi-node								   : False
2 - Multi-GPU								   : True
2 - Hostname								   : hpc-25-17.cm.cluster
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected
Traceback (most recent call last):
  File "main.py", line 242, in <module>
    main(params)
  File "main.py", line 165, in main
    init_distributed_mode(params)
  File "/central/home/aypan/enc_dec/src/slurm.py", line 155, in init_distributed_mode
    torch.cuda.set_device(params.local_rank)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 245, in set_device
    torch._C._cuda_setDevice(device)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 153, in _lazy_init
0 - Master address: 127.0.0.1
0 - Master port   : 29500
3 - Number of nodes: 1
3 - Node ID									   : 0
3 - Local rank								   : 3
3 - Global rank    : 3
3 - World size								   : 4
3 - GPUs per node  : 4
3 - Master									   : False
3 - Multi-node								   : False
3 - Multi-GPU								   : True
3 - Hostname								   : hpc-25-17.cm.cluster
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected
Traceback (most recent call last):
  File "main.py", line 242, in <module>
    torch._C._cuda_init()
RuntimeError: cuda runtime error (100) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp:47
    main(params)
  File "main.py", line 165, in main
    init_distributed_mode(params)
  File "/central/home/aypan/enc_dec/src/slurm.py", line 155, in init_distributed_mode
    torch.cuda.set_device(params.local_rank)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 245, in set_device
    torch._C._cuda_setDevice(device)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 153, in _lazy_init
    torch._C._cuda_init()
RuntimeError: cuda runtime error (100) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp:47
Traceback (most recent call last):
  File "/home/aypan/miniconda3/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/aypan/miniconda3/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/distributed/launch.py", line 263, in <module>
    main()
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/distributed/launch.py", line 259, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/aypan/miniconda3/bin/python3', '-u', 'main.py', '--local_rank=3', '--exp_name', 'treelstm_noparaminit_eval', '--eval_only', 'true', '--reload_model', 'dumped/treelstm_noinit/10976003/best-valid_ode2_acc.pth', '--beam_eval', 'true', '--beam_size', '10', '--beam_length_penalty', '1.0', '--beam_early_stopping', '1', '--eval_verbose', '1', '--eval_verbose_print', 'false', '--emb_dim', '256', '--n_dec_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--treelstm', '--symmetric', '--num_bit', '10', '--optimizer', 'adam,lr=0.0001', '--batch_size', '32', '--tasks', 'ode2', '--reload_data', 'ode2,ode2.train,ode2.valid,ode2.test']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
done
