SLURM job: True
1
0 - SLURM_JOB_ID: 10967967
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 30735
0
SLURM job: True
2
0 - SLURM_JOB_ID: 10967967
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 30735
0
SLURM job: True
0
0 - SLURM_JOB_ID: 10967967
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 30735
0
SLURM job: True
3
0 - SLURM_JOB_ID: 10967967
0 - SLURM_JOB_NODELIST: hpc-25-17
0 - SLURM_JOB_NUM_NODES: 1
0 - SLURM_NTASKS: 1
0 - SLURM_TASKS_PER_NODE: 1
0 - SLURM_MEM_PER_NODE: None
0 - SLURM_MEM_PER_CPU: 4096
0 - SLURM_NODEID: 0
0 - SLURM_PROCID: 0
0 - SLURM_LOCALID: 0
0 - SLURM_TASK_PID: 30735
0
0 - Master address: hpc-25-17
0 - Master port   : -1
0 - Number of nodes: 1
0 - Node ID			   : 0
0 - Local rank		   : 0
0 - Global rank    : 0
0 - World size		   : 1
0 - GPUs per node  : 1
0 - Master			   : True
0 - Multi-node		   : False
0 - Multi-GPU		   : False
0 - Hostname		   : hpc-25-17.cm.cluster
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected
Traceback (most recent call last):
  File "main.py", line 242, in <module>
    main(params)
  File "main.py", line 165, in main
    init_distributed_mode(params)
  File "/central/home/aypan/enc_dec/src/slurm.py", line 156, in init_distributed_mode
    torch.cuda.set_device(params.local_rank)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 245, in set_device
    torch._C._cuda_setDevice(device)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 153, in _lazy_init
    torch._C._cuda_init()
RuntimeError: cuda runtime error (100) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp:47
0 - Master address: hpc-25-17
0 - Master port   : -1
0 - Number of nodes: 1
0 - Node ID			   : 0
0 - Local rank		   : 0
0 - Global rank    : 0
0 - World size		   : 1
0 - GPUs per node  : 1
0 - Master			   : True
0 - Multi-node		   : False
0 - Multi-GPU		   : False
0 - Hostname		   : hpc-25-17.cm.cluster
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected
Traceback (most recent call last):
  File "main.py", line 242, in <module>
    main(params)
  File "main.py", line 165, in main
    init_distributed_mode(params)
  File "/central/home/aypan/enc_dec/src/slurm.py", line 156, in init_distributed_mode
    torch.cuda.set_device(params.local_rank)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 245, in set_device
    torch._C._cuda_setDevice(device)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 153, in _lazy_init
0 - Master address: hpc-25-17
0 - Master port   : -1
0 - Number of nodes: 1
0 - Node ID			   : 0
0 - Local rank		   : 0
0 - Global rank    : 0
0 - World size		   : 1
0 - GPUs per node  : 1
0 - Master			   : True
0 - Multi-node		   : False
0 - Multi-GPU		   : False
0 - Hostname		   : hpc-25-17.cm.cluster
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected
Traceback (most recent call last):
  File "main.py", line 242, in <module>
    torch._C._cuda_init()
RuntimeError: cuda runtime error (100) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp:47
    main(params)
  File "main.py", line 165, in main
    init_distributed_mode(params)
  File "/central/home/aypan/enc_dec/src/slurm.py", line 156, in init_distributed_mode
    torch.cuda.set_device(params.local_rank)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 245, in set_device
    torch._C._cuda_setDevice(device)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 153, in _lazy_init
    torch._C._cuda_init()
RuntimeError: cuda runtime error (100) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp:47
0 - Master address: hpc-25-17
0 - Master port   : -1
0 - Number of nodes: 1
0 - Node ID			   : 0
0 - Local rank		   : 0
0 - Global rank    : 0
0 - World size		   : 1
0 - GPUs per node  : 1
0 - Master			   : True
0 - Multi-node		   : False
0 - Multi-GPU		   : False
0 - Hostname		   : hpc-25-17.cm.cluster
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected
Traceback (most recent call last):
  File "main.py", line 242, in <module>
    main(params)
  File "main.py", line 165, in main
    init_distributed_mode(params)
  File "/central/home/aypan/enc_dec/src/slurm.py", line 156, in init_distributed_mode
    torch.cuda.set_device(params.local_rank)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 245, in set_device
    torch._C._cuda_setDevice(device)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py", line 153, in _lazy_init
    torch._C._cuda_init()
RuntimeError: cuda runtime error (100) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/THC/THCGeneral.cpp:47
Traceback (most recent call last):
  File "/home/aypan/miniconda3/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/aypan/miniconda3/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/distributed/launch.py", line 263, in <module>
    main()
  File "/home/aypan/miniconda3/lib/python3.7/site-packages/torch/distributed/launch.py", line 259, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/aypan/miniconda3/bin/python3', '-u', 'main.py', '--local_rank=3', '--exp_name', 'treelstm_noinit', '--tasks', 'ode2', '--reload_data', 'ode2,ode2.train,ode2.valid,ode2.test', '--reload_size', '100', '--emb_dim', '256', '--n_dec_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--treelstm', '--symmetric', '--num_bit', '10', '--optimizer', 'adam,lr=0.0001', '--batch_size', '32', '--epoch_size', '100', '--max_epoch', '10', '--validation_metrics', 'valid_ode2_acc']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
done
